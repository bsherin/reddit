{
    "sourceFile": "average/average_trajectories_smart.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 27,
            "patches": [
                {
                    "date": 1730058044759,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1730058520746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,13 +49,13 @@\n     \n \n print(\"done with globals\")\n class AverageTrajectories():\n-    def __init__(self, folder_of_models, exp, min_posts=2000):\n+    def __init__(self, folder_of_models, use_exp, min_posts=2000):\n         self.folder_of_models = folder_of_models\n         self.html_table = html_table\n         self.min_posts = min_posts\n-        self.exp = exp\n+        self.use_exp = use_exp\n         return\n \n     def display_status(self, text):\n         print(text)\n@@ -75,13 +75,19 @@\n         for item in os.listdir(self.folder_of_models):\n             item_path = os.path.join(self.folder_of_models, item)\n             # Check if the item is a directory\n             if os.path.isdir(item_path):\n+                if \"_snapshots\" not in item_path:\n+                    continue\n+                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", names=[\"key\", \"value\"], index_col=\"key\")\n+                is_exp = \"threshold_in_days\" in param_df.index\n+                if self.use_exp != is_exp:\n+                    continue\n                 fdict = {}\n                 for stage_kind in stage_kinds:\n                     fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n                 trajectories.append(fdict)\n-                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", names=[\"key\", \"value\"], index_col=\"key\")\n+                \n                 uids.append(param_df.loc[\"uid\"].value)\n                 seeds.append(param_df.loc[\"seed\"].value)\n                 param_df = param_df.drop([\"uid\", \"seed\"])\n                 if subreddit is None:\n@@ -150,7 +156,7 @@\n             f.write(the_html)\n \n if __name__ == '__main__':\n     print(\"starting\")\n-    exp = sys.argv[2].lower() == 'true'\n-    Tile = AverageTrajectories(sys.argv[1], exp, sys.argv[3])\n+    use_exp = sys.argv[2].lower() == 'true'\n+    Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n     Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730058854019,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n             # Check if the item is a directory\n             if os.path.isdir(item_path):\n                 if \"_snapshots\" not in item_path:\n                     continue\n-                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", names=[\"key\", \"value\"], index_col=\"key\")\n+                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n                 is_exp = \"threshold_in_days\" in param_df.index\n                 if self.use_exp != is_exp:\n                     continue\n                 fdict = {}\n"
                },
                {
                    "date": 1730062765932,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n         }\n \n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n         the_html = rclass.render_content()\n-        if is_exp:\n+        if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n         else:\n             fname = f\"{subreddit}_avg\"\n         with open(f\"{self.folder_of_models}/{fname}.html\", \"w\") as f:\n"
                },
                {
                    "date": 1730150034385,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n         \n         subreddit = None\n         \n         uids = []\n-        seeds = []\n+        run_numbers = []\n         \n         common_param_df = None\n         common_key_info = None\n         \n@@ -87,10 +87,14 @@\n                     fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n                 trajectories.append(fdict)\n                 \n                 uids.append(param_df.loc[\"uid\"].value)\n-                seeds.append(param_df.loc[\"seed\"].value)\n-                param_df = param_df.drop([\"uid\", \"seed\"])\n+                if \"run_number\" in param_df.index:\n+                    run_numbers.append(param_df.loc[\"run_number\"].value)\n+                    param_df = param_df.drop([\"uid\", \"run_number\"])\n+                else:\n+                    run_numbers.append(param_df.loc[\"seed\"].value)\n+                    param_df = param_df.drop([\"uid\", \"seed\"])\n                 if subreddit is None:\n                     bn = os.path.basename(item_path)\n                     subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n                     is_exp = is_exp_sampling(param_df)\n"
                },
                {
                    "date": 1730150175807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,9 +116,9 @@\n         \n         self.param_df = common_param_df\n         self.key_info = common_key_info\n         self.uids = uids\n-        self.seeds = seeds\n+        self.run_numbers = run_numbers\n         self.subreddit = subreddit\n         self.is_exp = is_exp\n         \n         if self.is_exp:\n@@ -145,9 +145,9 @@\n             \"param_df\": getattr(Tile, \"param_df\"),\n             \"key_info\": getattr(Tile, \"key_info\"),\n             \"uids\": getattr(Tile, \"uids\"),\n             \"subreddit\": getattr(Tile, \"subreddit\"),\n-            \"seeds\": getattr(Tile, \"seeds\"),\n+            \"run_numbers\": getattr(Tile, \"rnum_numbers\"),\n             \"is_exp\": getattr(Tile, \"is_exp\"),\n         }\n \n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n"
                },
                {
                    "date": 1730155824156,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,9 +145,9 @@\n             \"param_df\": getattr(Tile, \"param_df\"),\n             \"key_info\": getattr(Tile, \"key_info\"),\n             \"uids\": getattr(Tile, \"uids\"),\n             \"subreddit\": getattr(Tile, \"subreddit\"),\n-            \"run_numbers\": getattr(Tile, \"rnum_numbers\"),\n+            \"run_numbers\": getattr(Tile, \"run_numbers\"),\n             \"is_exp\": getattr(Tile, \"is_exp\"),\n         }\n \n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n"
                },
                {
                    "date": 1730212778667,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,174 @@\n+print(\"starting\")\n+import pickle\n+import json\n+import sys\n+import pickle\n+import os\n+import pandas as pd\n+from pandas import Timedelta\n+import re\n+import json\n+\n+from build_average_trajectory_report import BuildAverageTrajectoryReport\n+from utilities import html_table\n+\n+y_axis_labels = {\n+    \"num_phases\": \"phase\",\n+    \"raw_post_count\": \"posts\",\n+    \"time\": \"weeks\",\n+    \"experience\": \"pseudo weeks\",\n+    \"ntokens_bins\": \"ntokens\"\n+}\n+\n+stage_kinds = [\"num_phases\", \"raw_post_count\", \"time\", \"experience\"]\n+\n+def ds(text):\n+    print(text)\n+\n+def load_pickle_or_parquet(path):\n+    fname, ext = os.path.splitext(path)\n+    if ext == \".parquet\":\n+        return pd.read_parquet(path)\n+    else:\n+        return pd.read_pickle(path)\n+\n+def is_exp_sampling(param_df):\n+    return \"threshold_in_days\" in param_df.index\n+\n+def compare_dataframes(df1, df2):\n+    if df1.index.equals(df2.index) and (df1['value'] == df2['value']).all():\n+        return True\n+    else:\n+        return False\n+\n+def compare_dicts(d1, d2):\n+    for k in d1.keys():\n+        if not d1[k] == d2[k]:\n+            return False\n+    return True\n+    \n+\n+print(\"done with globals\")\n+class AverageTrajectories():\n+    def __init__(self, folder_of_models, use_exp, min_posts=2000):\n+        self.folder_of_models = folder_of_models\n+        self.html_table = html_table\n+        self.min_posts = min_posts\n+        self.use_exp = use_exp\n+        return\n+\n+    def display_status(self, text):\n+        print(text)\n+\n+    def render_content(self):\n+        trajectories = []\n+        params = []\n+        \n+        subreddit = None\n+        \n+        uids = []\n+        run_numbers = []\n+        \n+        common_param_df = None\n+        common_key_info = None\n+\n+        if self.use_exp:\n+            output_folder = f\"{self.folder_of_models}/exp_avg\"\n+        else:\n+            output_folder = f\"{self.folder_of_models}/avg\"\n+        if not os.path.exists(output_folder):\n+            os.makedirs(output_folder)\n+        \n+        for item in os.listdir(self.folder_of_models):\n+            item_path = os.path.join(self.folder_of_models, item)\n+            # Check if the item is a directory\n+            if os.path.isdir(item_path):\n+                if \"_snapshots\" not in item_path:\n+                    continue\n+                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n+                is_exp = \"threshold_in_days\" in param_df.index\n+                if self.use_exp != is_exp:\n+                    continue\n+                fdict = {}\n+                for stage_kind in stage_kinds:\n+                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n+                trajectories.append(fdict)\n+                \n+                uids.append(param_df.loc[\"uid\"].value)\n+                if \"run_number\" in param_df.index:\n+                    run_numbers.append(param_df.loc[\"run_number\"].value)\n+                    param_df = param_df.drop([\"uid\", \"run_number\"])\n+                else:\n+                    run_numbers.append(param_df.loc[\"seed\"].value)\n+                    param_df = param_df.drop([\"uid\", \"seed\"])\n+                if subreddit is None:\n+                    bn = os.path.basename(item_path)\n+                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n+                    is_exp = is_exp_sampling(param_df)\n+                    common_param_df = param_df\n+                if not compare_dataframes(param_df, common_param_df):\n+                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                    the_html += self.html_table(param_df, sidebyside=True)\n+                    the_html += self.html_table(common_param_df, sidebyside=True)\n+                    return the_html\n+                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n+                    key_info = json.load(f)\n+                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n+                if common_key_info is None:\n+                    common_key_info = key_info\n+                if not compare_dicts(key_info, common_key_info):\n+                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                    the_html += self.html_table(key_info, sidebyside=True)\n+                    the_html += self.html_table(common_key_info, sidebyside=True)\n+        \n+        self.param_df = common_param_df\n+        self.key_info = common_key_info\n+        self.uids = uids\n+        self.run_numbers = run_numbers\n+        self.subreddit = subreddit\n+        self.is_exp = is_exp\n+        \n+        if self.is_exp:\n+            self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n+        else:\n+            self.table_html = f\"<h4>{subreddit}</h4>\"\n+        self.table_html += self.html_table(common_param_df, sidebyside=True)\n+        self.table_html += self.html_table(common_key_info, sidebyside=True)\n+        self.table_html += \"<br>\"\n+        ds(\"computing averages\")\n+        for stage_kind in stage_kinds:\n+            dfs = []\n+            for fdict in trajectories:\n+                dfs.append(fdict[stage_kind])\n+            combined_df = pd.concat(dfs)\n+            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n+            setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n+            result_df.to_parquet(f\"{output_folder}/{stage_kind}_trajectory_df.parquet\")\n+        results = {\n+            \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n+            \"raw_post_count_trajectory_df\": getattr(Tile, \"raw_post_count_trajectory_df\"),\n+            \"time_trajectory_df\": getattr(Tile, \"time_trajectory_df\"),\n+            \"experience_trajectory_df\": getattr(Tile, \"experience_trajectory_df\"),\n+            # \"ntokens_bins_trajectory_df\": getattr(Tile, \"ntokens_bins_trajectory_df\"),\n+            \"param_df\": getattr(Tile, \"param_df\"),\n+            \"key_info\": getattr(Tile, \"key_info\"),\n+            \"uids\": getattr(Tile, \"uids\"),\n+            \"subreddit\": getattr(Tile, \"subreddit\"),\n+            \"run_numbers\": getattr(Tile, \"run_numbers\"),\n+            \"is_exp\": getattr(Tile, \"is_exp\"),\n+        }\n+\n+        rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n+        the_html = rclass.render_content()\n+        if self.use_exp:\n+            fname = f\"{subreddit}_avg_exp\"\n+        else:\n+            fname = f\"{subreddit}_avg\"\n+        with open(f\"{self.folder_of_models}/{fname}.html\", \"w\") as f:\n+            f.write(the_html)\n+\n+if __name__ == '__main__':\n+    print(\"starting\")\n+    use_exp = sys.argv[2].lower() == 'true'\n+    Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n+    Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730213009298,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n import re\n import json\n \n from build_average_trajectory_report import BuildAverageTrajectoryReport\n-from utilities import html_table\n+from utilities import html_table, save_to_json\n \n y_axis_labels = {\n     \"num_phases\": \"phase\",\n     \"raw_post_count\": \"posts\",\n@@ -156,9 +156,10 @@\n             \"subreddit\": getattr(Tile, \"subreddit\"),\n             \"run_numbers\": getattr(Tile, \"run_numbers\"),\n             \"is_exp\": getattr(Tile, \"is_exp\"),\n         }\n-\n+        save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n+        results[\"param_df\"].to_parquet(f\"{output_folder}/parameters.txt\", sep=\":\\t\")\n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n         the_html = rclass.render_content()\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n@@ -170,171 +171,5 @@\n if __name__ == '__main__':\n     print(\"starting\")\n     use_exp = sys.argv[2].lower() == 'true'\n     Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n-    Tile.render_content()\n-print(\"starting\")\n-import pickle\n-import json\n-import sys\n-import pickle\n-import os\n-import pandas as pd\n-from pandas import Timedelta\n-import re\n-import json\n-\n-from build_average_trajectory_report import BuildAverageTrajectoryReport\n-from utilities import html_table\n-\n-y_axis_labels = {\n-    \"num_phases\": \"phase\",\n-    \"raw_post_count\": \"posts\",\n-    \"time\": \"weeks\",\n-    \"experience\": \"pseudo weeks\",\n-    \"ntokens_bins\": \"ntokens\"\n-}\n-\n-stage_kinds = [\"num_phases\", \"raw_post_count\", \"time\", \"experience\"]\n-\n-def ds(text):\n-    print(text)\n-\n-def load_pickle_or_parquet(path):\n-    fname, ext = os.path.splitext(path)\n-    if ext == \".parquet\":\n-        return pd.read_parquet(path)\n-    else:\n-        return pd.read_pickle(path)\n-\n-def is_exp_sampling(param_df):\n-    return \"threshold_in_days\" in param_df.index\n-\n-def compare_dataframes(df1, df2):\n-    if df1.index.equals(df2.index) and (df1['value'] == df2['value']).all():\n-        return True\n-    else:\n-        return False\n-\n-def compare_dicts(d1, d2):\n-    for k in d1.keys():\n-        if not d1[k] == d2[k]:\n-            return False\n-    return True\n-    \n-\n-print(\"done with globals\")\n-class AverageTrajectories():\n-    def __init__(self, folder_of_models, use_exp, min_posts=2000):\n-        self.folder_of_models = folder_of_models\n-        self.html_table = html_table\n-        self.min_posts = min_posts\n-        self.use_exp = use_exp\n-        return\n-\n-    def display_status(self, text):\n-        print(text)\n-\n-    def render_content(self):\n-        trajectories = []\n-        params = []\n-        \n-        subreddit = None\n-        \n-        uids = []\n-        run_numbers = []\n-        \n-        common_param_df = None\n-        common_key_info = None\n-        \n-        for item in os.listdir(self.folder_of_models):\n-            item_path = os.path.join(self.folder_of_models, item)\n-            # Check if the item is a directory\n-            if os.path.isdir(item_path):\n-                if \"_snapshots\" not in item_path:\n-                    continue\n-                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n-                is_exp = \"threshold_in_days\" in param_df.index\n-                if self.use_exp != is_exp:\n-                    continue\n-                fdict = {}\n-                for stage_kind in stage_kinds:\n-                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n-                trajectories.append(fdict)\n-                \n-                uids.append(param_df.loc[\"uid\"].value)\n-                if \"run_number\" in param_df.index:\n-                    run_numbers.append(param_df.loc[\"run_number\"].value)\n-                    param_df = param_df.drop([\"uid\", \"run_number\"])\n-                else:\n-                    run_numbers.append(param_df.loc[\"seed\"].value)\n-                    param_df = param_df.drop([\"uid\", \"seed\"])\n-                if subreddit is None:\n-                    bn = os.path.basename(item_path)\n-                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n-                    is_exp = is_exp_sampling(param_df)\n-                    common_param_df = param_df\n-                if not compare_dataframes(param_df, common_param_df):\n-                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(param_df, sidebyside=True)\n-                    the_html += self.html_table(common_param_df, sidebyside=True)\n-                    return the_html\n-                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n-                    key_info = json.load(f)\n-                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n-                if common_key_info is None:\n-                    common_key_info = key_info\n-                if not compare_dicts(key_info, common_key_info):\n-                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(key_info, sidebyside=True)\n-                    the_html += self.html_table(common_key_info, sidebyside=True)\n-        \n-        self.param_df = common_param_df\n-        self.key_info = common_key_info\n-        self.uids = uids\n-        self.run_numbers = run_numbers\n-        self.subreddit = subreddit\n-        self.is_exp = is_exp\n-        \n-        if self.is_exp:\n-            self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n-        else:\n-            self.table_html = f\"<h4>{subreddit}</h4>\"\n-        self.table_html += self.html_table(common_param_df, sidebyside=True)\n-        self.table_html += self.html_table(common_key_info, sidebyside=True)\n-        self.table_html += \"<br>\"\n-        ds(\"computing averages\")\n-        for stage_kind in stage_kinds:\n-            dfs = []\n-            for fdict in trajectories:\n-                dfs.append(fdict[stage_kind])\n-            combined_df = pd.concat(dfs)\n-            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n-            setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n-        results = {\n-            \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n-            \"raw_post_count_trajectory_df\": getattr(Tile, \"raw_post_count_trajectory_df\"),\n-            \"time_trajectory_df\": getattr(Tile, \"time_trajectory_df\"),\n-            \"experience_trajectory_df\": getattr(Tile, \"experience_trajectory_df\"),\n-            # \"ntokens_bins_trajectory_df\": getattr(Tile, \"ntokens_bins_trajectory_df\"),\n-            \"param_df\": getattr(Tile, \"param_df\"),\n-            \"key_info\": getattr(Tile, \"key_info\"),\n-            \"uids\": getattr(Tile, \"uids\"),\n-            \"subreddit\": getattr(Tile, \"subreddit\"),\n-            \"run_numbers\": getattr(Tile, \"run_numbers\"),\n-            \"is_exp\": getattr(Tile, \"is_exp\"),\n-        }\n-\n-        rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n-        the_html = rclass.render_content()\n-        if self.use_exp:\n-            fname = f\"{subreddit}_avg_exp\"\n-        else:\n-            fname = f\"{subreddit}_avg\"\n-        with open(f\"{self.folder_of_models}/{fname}.html\", \"w\") as f:\n-            f.write(the_html)\n-\n-if __name__ == '__main__':\n-    print(\"starting\")\n-    use_exp = sys.argv[2].lower() == 'true'\n-    Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n     Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730213671022,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,12 +55,19 @@\n         self.html_table = html_table\n         self.min_posts = min_posts\n         self.use_exp = use_exp\n         return\n-\n+    \n     def display_status(self, text):\n         print(text)\n \n+    def get_param_string(self, param_df):\n+        pdict = param_df[\"value\"].to_dict()\n+        for p, v in pdict.items():\n+            pstr += f\"{p}:\\t{str(v)}\\n\"\n+        return pstr\n+    \n+\n     def render_content(self):\n         trajectories = []\n         params = []\n         \n@@ -157,9 +164,10 @@\n             \"run_numbers\": getattr(Tile, \"run_numbers\"),\n             \"is_exp\": getattr(Tile, \"is_exp\"),\n         }\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n-        results[\"param_df\"].to_parquet(f\"{output_folder}/parameters.txt\", sep=\":\\t\")\n+\n+        \n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n         the_html = rclass.render_content()\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n"
                },
                {
                    "date": 1730213735175,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,10 +164,10 @@\n             \"run_numbers\": getattr(Tile, \"run_numbers\"),\n             \"is_exp\": getattr(Tile, \"is_exp\"),\n         }\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n-\n-        \n+        with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n+            f.write(self.get_param_string(results[\"param_df\"]))\n         rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n         the_html = rclass.render_content()\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n"
                },
                {
                    "date": 1730213958644,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,8 +61,9 @@\n         print(text)\n \n     def get_param_string(self, param_df):\n         pdict = param_df[\"value\"].to_dict()\n+        pstr = \"\"\n         for p, v in pdict.items():\n             pstr += f\"{p}:\\t{str(v)}\\n\"\n         return pstr\n     \n"
                },
                {
                    "date": 1730214117301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -173,9 +173,9 @@\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n         else:\n             fname = f\"{subreddit}_avg\"\n-        with open(f\"{self.folder_of_models}/{fname}.html\", \"w\") as f:\n+        with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n             f.write(the_html)\n \n if __name__ == '__main__':\n     print(\"starting\")\n"
                },
                {
                    "date": 1730214274314,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -175,8 +175,10 @@\n         else:\n             fname = f\"{subreddit}_avg\"\n         with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n             f.write(the_html)\n+        with open(f\"{output_folder}/results.pickle\", \"wb\") as f:\n+            pickle.dump(results, f)\n \n if __name__ == '__main__':\n     print(\"starting\")\n     use_exp = sys.argv[2].lower() == 'true'\n"
                },
                {
                    "date": 1730214724374,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -167,9 +167,10 @@\n         }\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n         with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n             f.write(self.get_param_string(results[\"param_df\"]))\n-        rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n+        # source, fn, fv, fk, marker_size=8\n+        rclass = BuildAverageTrajectoryReport(results, \"min_posts\", self.min_posts, \">=\")\n         the_html = rclass.render_content()\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n         else:\n@@ -181,6 +182,7 @@\n \n if __name__ == '__main__':\n     print(\"starting\")\n     use_exp = sys.argv[2].lower() == 'true'\n+    # folder_of_models, use_exp, min_posts=2000\n     Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n     Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730215460542,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -176,9 +176,9 @@\n         else:\n             fname = f\"{subreddit}_avg\"\n         with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n             f.write(the_html)\n-        with open(f\"{output_folder}/results.pickle\", \"wb\") as f:\n+        with open(f\"{output_folder}/{fname}_results.pickle\", \"wb\") as f:\n             pickle.dump(results, f)\n \n if __name__ == '__main__':\n     print(\"starting\")\n"
                },
                {
                    "date": 1730216114131,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -168,9 +168,9 @@\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n         with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n             f.write(self.get_param_string(results[\"param_df\"]))\n         # source, fn, fv, fk, marker_size=8\n-        rclass = BuildAverageTrajectoryReport(results, \"min_posts\", self.min_posts, \">=\")\n+        rclass = BuildAverageTrajectoryReport(results, \"nposts\", self.min_posts, \">=\")\n         the_html = rclass.render_content()\n         if self.use_exp:\n             fname = f\"{subreddit}_avg_exp\"\n         else:\n"
                },
                {
                    "date": 1730216659831,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -176,9 +176,9 @@\n         else:\n             fname = f\"{subreddit}_avg\"\n         with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n             f.write(the_html)\n-        with open(f\"{output_folder}/{fname}_results.pickle\", \"wb\") as f:\n+        with open(f\"{output_folder}/{fname}_results.pkl\", \"wb\") as f:\n             pickle.dump(results, f)\n \n if __name__ == '__main__':\n     print(\"starting\")\n"
                },
                {
                    "date": 1730231210754,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,11 +133,10 @@\n         self.key_info = common_key_info\n         self.uids = uids\n         self.run_numbers = run_numbers\n         self.subreddit = subreddit\n-        self.is_exp = is_exp\n         \n-        if self.is_exp:\n+        if self.use_exp:\n             self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n         else:\n             self.table_html = f\"<h4>{subreddit}</h4>\"\n         self.table_html += self.html_table(common_param_df, sidebyside=True)\n@@ -162,9 +161,9 @@\n             \"key_info\": getattr(Tile, \"key_info\"),\n             \"uids\": getattr(Tile, \"uids\"),\n             \"subreddit\": getattr(Tile, \"subreddit\"),\n             \"run_numbers\": getattr(Tile, \"run_numbers\"),\n-            \"is_exp\": getattr(Tile, \"is_exp\"),\n+            \"is_exp\": getattr(Tile, \"use_exp\"),\n         }\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n         with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n             f.write(self.get_param_string(results[\"param_df\"]))\n"
                },
                {
                    "date": 1730301988846,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,188 @@\n+print(\"starting\")\n+import pickle\n+import json\n+import sys\n+import pickle\n+import os\n+import pandas as pd\n+from pandas import Timedelta\n+import re\n+import json\n+\n+from build_average_trajectory_report import BuildAverageTrajectoryReport\n+from utilities import html_table, save_to_json\n+\n+y_axis_labels = {\n+    \"num_phases\": \"phase\",\n+    \"raw_post_count\": \"posts\",\n+    \"time\": \"weeks\",\n+    \"experience\": \"pseudo weeks\",\n+    \"ntokens_bins\": \"ntokens\"\n+}\n+\n+stage_kinds = [\"num_phases\", \"raw_post_count\", \"time\", \"experience\"]\n+\n+def ds(text):\n+    print(text)\n+\n+def load_pickle_or_parquet(path):\n+    fname, ext = os.path.splitext(path)\n+    if ext == \".parquet\":\n+        return pd.read_parquet(path)\n+    else:\n+        return pd.read_pickle(path)\n+\n+def is_exp_sampling(param_df):\n+    return \"threshold_in_days\" in param_df.index\n+\n+def compare_dataframes(df1, df2):\n+    if df1.index.equals(df2.index) and (df1['value'] == df2['value']).all():\n+        return True\n+    else:\n+        return False\n+\n+def compare_dicts(d1, d2):\n+    for k in d1.keys():\n+        if not d1[k] == d2[k]:\n+            return False\n+    return True\n+    \n+\n+print(\"done with globals\")\n+class AverageTrajectories():\n+    def __init__(self, folder_of_models, use_exp, min_posts=2000):\n+        self.folder_of_models = folder_of_models\n+        self.html_table = html_table\n+        self.min_posts = min_posts\n+        self.use_exp = use_exp\n+        return\n+    \n+    def display_status(self, text):\n+        print(text)\n+\n+    def get_param_string(self, param_df):\n+        pdict = param_df[\"value\"].to_dict()\n+        pstr = \"\"\n+        for p, v in pdict.items():\n+            pstr += f\"{p}:\\t{str(v)}\\n\"\n+        return pstr\n+    \n+\n+    def render_content(self):\n+        trajectories = []\n+        params = []\n+        \n+        subreddit = None\n+        \n+        uids = []\n+        run_numbers = []\n+        \n+        common_param_df = None\n+        common_key_info = None\n+\n+        if self.use_exp:\n+            output_folder = f\"{self.folder_of_models}/exp_avg\"\n+        else:\n+            output_folder = f\"{self.folder_of_models}/avg\"\n+        if not os.path.exists(output_folder):\n+            os.makedirs(output_folder)\n+        \n+        for item in os.listdir(self.folder_of_models):\n+            item_path = os.path.join(self.folder_of_models, item)\n+            # Check if the item is a directory\n+            if os.path.isdir(item_path):\n+                if \"_snapshots\" not in item_path:\n+                    continue\n+                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n+                is_exp = \"threshold_in_days\" in param_df.index\n+                if self.use_exp != is_exp:\n+                    continue\n+                fdict = {}\n+                for stage_kind in stage_kinds:\n+                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n+                trajectories.append(fdict)\n+                \n+                uids.append(param_df.loc[\"uid\"].value)\n+                if \"run_number\" in param_df.index:\n+                    run_numbers.append(param_df.loc[\"run_number\"].value)\n+                    param_df = param_df.drop([\"uid\", \"run_number\"])\n+                else:\n+                    run_numbers.append(param_df.loc[\"seed\"].value)\n+                    param_df = param_df.drop([\"uid\", \"seed\"])\n+                if subreddit is None:\n+                    bn = os.path.basename(item_path)\n+                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n+                    is_exp = is_exp_sampling(param_df)\n+                    common_param_df = param_df\n+                if not compare_dataframes(param_df, common_param_df):\n+                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                    the_html += self.html_table(param_df, sidebyside=True)\n+                    the_html += self.html_table(common_param_df, sidebyside=True)\n+                    return the_html\n+                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n+                    key_info = json.load(f)\n+                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n+                if common_key_info is None:\n+                    common_key_info = key_info\n+                if not compare_dicts(key_info, common_key_info):\n+                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                    the_html += self.html_table(key_info, sidebyside=True)\n+                    the_html += self.html_table(common_key_info, sidebyside=True)\n+        \n+        self.param_df = common_param_df\n+        self.key_info = common_key_info\n+        self.uids = uids\n+        self.run_numbers = run_numbers\n+        self.subreddit = subreddit\n+        \n+        if self.use_exp:\n+            self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n+        else:\n+            self.table_html = f\"<h4>{subreddit}</h4>\"\n+        self.table_html += self.html_table(common_param_df, sidebyside=True)\n+        self.table_html += self.html_table(common_key_info, sidebyside=True)\n+        self.table_html += \"<br>\"\n+        ds(\"computing averages\")\n+        for stage_kind in stage_kinds:\n+            dfs = []\n+            for fdict in trajectories:\n+                dfs.append(fdict[stage_kind])\n+            combined_df = pd.concat(dfs)\n+            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n+            setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n+            result_df.to_parquet(f\"{output_folder}/{stage_kind}_trajectory_df.parquet\")\n+        results = {\n+            \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n+            \"raw_post_count_trajectory_df\": getattr(Tile, \"raw_post_count_trajectory_df\"),\n+            \"time_trajectory_df\": getattr(Tile, \"time_trajectory_df\"),\n+            \"experience_trajectory_df\": getattr(Tile, \"experience_trajectory_df\"),\n+            # \"ntokens_bins_trajectory_df\": getattr(Tile, \"ntokens_bins_trajectory_df\"),\n+            \"param_df\": getattr(Tile, \"param_df\"),\n+            \"key_info\": getattr(Tile, \"key_info\"),\n+            \"uids\": getattr(Tile, \"uids\"),\n+            \"subreddit\": getattr(Tile, \"subreddit\"),\n+            \"run_numbers\": getattr(Tile, \"run_numbers\"),\n+            \"is_exp\": getattr(Tile, \"use_exp\"),\n+        }\n+        save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n+        with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n+            f.write(self.get_param_string(results[\"param_df\"]))\n+        # source, fn, fv, fk, marker_size=8\n+        rclass = BuildAverageTrajectoryReport(results, \"nposts\", self.min_posts, \">=\")\n+        the_html = rclass.render_content()\n+        if self.use_exp:\n+            fname = f\"{subreddit}_avg_exp\"\n+        else:\n+            fname = f\"{subreddit}_avg\"\n+        with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n+            f.write(the_html)\n+        with open(f\"{output_folder}/{fname}_results.pkl\", \"wb\") as f:\n+            pickle.dump(results, f)\n+\n+if __name__ == '__main__':\n+    print(\"starting\")\n+    use_exp = sys.argv[2].lower() == 'true'\n+    # folder_of_models, use_exp, min_posts=2000\n+    print(\"got folder\", sys.argv[1])\n+    Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n+    Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730302024373,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,8 +86,9 @@\n             output_folder = f\"{self.folder_of_models}/avg\"\n         if not os.path.exists(output_folder):\n             os.makedirs(output_folder)\n         \n+        print(\"looping over folder\")\n         for item in os.listdir(self.folder_of_models):\n             item_path = os.path.join(self.folder_of_models, item)\n             # Check if the item is a directory\n             if os.path.isdir(item_path):\n@@ -163,8 +164,9 @@\n             \"subreddit\": getattr(Tile, \"subreddit\"),\n             \"run_numbers\": getattr(Tile, \"run_numbers\"),\n             \"is_exp\": getattr(Tile, \"use_exp\"),\n         }\n+        print(\"writing results\")\n         save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n         with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n             f.write(self.get_param_string(results[\"param_df\"]))\n         # source, fn, fv, fk, marker_size=8\n@@ -184,192 +186,5 @@\n     use_exp = sys.argv[2].lower() == 'true'\n     # folder_of_models, use_exp, min_posts=2000\n     print(\"got folder\", sys.argv[1])\n     Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n-    Tile.render_content()\n-print(\"starting\")\n-import pickle\n-import json\n-import sys\n-import pickle\n-import os\n-import pandas as pd\n-from pandas import Timedelta\n-import re\n-import json\n-\n-from build_average_trajectory_report import BuildAverageTrajectoryReport\n-from utilities import html_table, save_to_json\n-\n-y_axis_labels = {\n-    \"num_phases\": \"phase\",\n-    \"raw_post_count\": \"posts\",\n-    \"time\": \"weeks\",\n-    \"experience\": \"pseudo weeks\",\n-    \"ntokens_bins\": \"ntokens\"\n-}\n-\n-stage_kinds = [\"num_phases\", \"raw_post_count\", \"time\", \"experience\"]\n-\n-def ds(text):\n-    print(text)\n-\n-def load_pickle_or_parquet(path):\n-    fname, ext = os.path.splitext(path)\n-    if ext == \".parquet\":\n-        return pd.read_parquet(path)\n-    else:\n-        return pd.read_pickle(path)\n-\n-def is_exp_sampling(param_df):\n-    return \"threshold_in_days\" in param_df.index\n-\n-def compare_dataframes(df1, df2):\n-    if df1.index.equals(df2.index) and (df1['value'] == df2['value']).all():\n-        return True\n-    else:\n-        return False\n-\n-def compare_dicts(d1, d2):\n-    for k in d1.keys():\n-        if not d1[k] == d2[k]:\n-            return False\n-    return True\n-    \n-\n-print(\"done with globals\")\n-class AverageTrajectories():\n-    def __init__(self, folder_of_models, use_exp, min_posts=2000):\n-        self.folder_of_models = folder_of_models\n-        self.html_table = html_table\n-        self.min_posts = min_posts\n-        self.use_exp = use_exp\n-        return\n-    \n-    def display_status(self, text):\n-        print(text)\n-\n-    def get_param_string(self, param_df):\n-        pdict = param_df[\"value\"].to_dict()\n-        pstr = \"\"\n-        for p, v in pdict.items():\n-            pstr += f\"{p}:\\t{str(v)}\\n\"\n-        return pstr\n-    \n-\n-    def render_content(self):\n-        trajectories = []\n-        params = []\n-        \n-        subreddit = None\n-        \n-        uids = []\n-        run_numbers = []\n-        \n-        common_param_df = None\n-        common_key_info = None\n-\n-        if self.use_exp:\n-            output_folder = f\"{self.folder_of_models}/exp_avg\"\n-        else:\n-            output_folder = f\"{self.folder_of_models}/avg\"\n-        if not os.path.exists(output_folder):\n-            os.makedirs(output_folder)\n-        \n-        for item in os.listdir(self.folder_of_models):\n-            item_path = os.path.join(self.folder_of_models, item)\n-            # Check if the item is a directory\n-            if os.path.isdir(item_path):\n-                if \"_snapshots\" not in item_path:\n-                    continue\n-                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n-                is_exp = \"threshold_in_days\" in param_df.index\n-                if self.use_exp != is_exp:\n-                    continue\n-                fdict = {}\n-                for stage_kind in stage_kinds:\n-                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n-                trajectories.append(fdict)\n-                \n-                uids.append(param_df.loc[\"uid\"].value)\n-                if \"run_number\" in param_df.index:\n-                    run_numbers.append(param_df.loc[\"run_number\"].value)\n-                    param_df = param_df.drop([\"uid\", \"run_number\"])\n-                else:\n-                    run_numbers.append(param_df.loc[\"seed\"].value)\n-                    param_df = param_df.drop([\"uid\", \"seed\"])\n-                if subreddit is None:\n-                    bn = os.path.basename(item_path)\n-                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n-                    is_exp = is_exp_sampling(param_df)\n-                    common_param_df = param_df\n-                if not compare_dataframes(param_df, common_param_df):\n-                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(param_df, sidebyside=True)\n-                    the_html += self.html_table(common_param_df, sidebyside=True)\n-                    return the_html\n-                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n-                    key_info = json.load(f)\n-                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n-                if common_key_info is None:\n-                    common_key_info = key_info\n-                if not compare_dicts(key_info, common_key_info):\n-                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(key_info, sidebyside=True)\n-                    the_html += self.html_table(common_key_info, sidebyside=True)\n-        \n-        self.param_df = common_param_df\n-        self.key_info = common_key_info\n-        self.uids = uids\n-        self.run_numbers = run_numbers\n-        self.subreddit = subreddit\n-        \n-        if self.use_exp:\n-            self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n-        else:\n-            self.table_html = f\"<h4>{subreddit}</h4>\"\n-        self.table_html += self.html_table(common_param_df, sidebyside=True)\n-        self.table_html += self.html_table(common_key_info, sidebyside=True)\n-        self.table_html += \"<br>\"\n-        ds(\"computing averages\")\n-        for stage_kind in stage_kinds:\n-            dfs = []\n-            for fdict in trajectories:\n-                dfs.append(fdict[stage_kind])\n-            combined_df = pd.concat(dfs)\n-            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n-            setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n-            result_df.to_parquet(f\"{output_folder}/{stage_kind}_trajectory_df.parquet\")\n-        results = {\n-            \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n-            \"raw_post_count_trajectory_df\": getattr(Tile, \"raw_post_count_trajectory_df\"),\n-            \"time_trajectory_df\": getattr(Tile, \"time_trajectory_df\"),\n-            \"experience_trajectory_df\": getattr(Tile, \"experience_trajectory_df\"),\n-            # \"ntokens_bins_trajectory_df\": getattr(Tile, \"ntokens_bins_trajectory_df\"),\n-            \"param_df\": getattr(Tile, \"param_df\"),\n-            \"key_info\": getattr(Tile, \"key_info\"),\n-            \"uids\": getattr(Tile, \"uids\"),\n-            \"subreddit\": getattr(Tile, \"subreddit\"),\n-            \"run_numbers\": getattr(Tile, \"run_numbers\"),\n-            \"is_exp\": getattr(Tile, \"use_exp\"),\n-        }\n-        save_to_json(results[\"key_info\"], f\"{output_folder}/trajectory_key_info.json\")\n-        with open(f\"{output_folder}/parameters.txt\", \"w\") as f:\n-            f.write(self.get_param_string(results[\"param_df\"]))\n-        # source, fn, fv, fk, marker_size=8\n-        rclass = BuildAverageTrajectoryReport(results, \"nposts\", self.min_posts, \">=\")\n-        the_html = rclass.render_content()\n-        if self.use_exp:\n-            fname = f\"{subreddit}_avg_exp\"\n-        else:\n-            fname = f\"{subreddit}_avg\"\n-        with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n-            f.write(the_html)\n-        with open(f\"{output_folder}/{fname}_results.pkl\", \"wb\") as f:\n-            pickle.dump(results, f)\n-\n-if __name__ == '__main__':\n-    print(\"starting\")\n-    use_exp = sys.argv[2].lower() == 'true'\n-    # folder_of_models, use_exp, min_posts=2000\n-    Tile = AverageTrajectories(sys.argv[1], use_exp, sys.argv[3])\n     Tile.render_content()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1730302740249,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -90,8 +90,9 @@\n         print(\"looping over folder\")\n         for item in os.listdir(self.folder_of_models):\n             item_path = os.path.join(self.folder_of_models, item)\n             # Check if the item is a directory\n+            print(\"got item path\", item_path)\n             if os.path.isdir(item_path):\n                 if \"_snapshots\" not in item_path:\n                     continue\n                 param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n@@ -128,9 +129,9 @@\n                 if not compare_dicts(key_info, common_key_info):\n                     the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n                     the_html += self.html_table(key_info, sidebyside=True)\n                     the_html += self.html_table(common_key_info, sidebyside=True)\n-        \n+        print(\"done looping over folder\")\n         self.param_df = common_param_df\n         self.key_info = common_key_info\n         self.uids = uids\n         self.run_numbers = run_numbers\n"
                },
                {
                    "date": 1730302847833,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,8 +94,9 @@\n             print(\"got item path\", item_path)\n             if os.path.isdir(item_path):\n                 if \"_snapshots\" not in item_path:\n                     continue\n+                print(\"item_path is a snapshot\")\n                 param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n                 is_exp = \"threshold_in_days\" in param_df.index\n                 if self.use_exp != is_exp:\n                     continue\n"
                },
                {
                    "date": 1730303533668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,50 +88,55 @@\n             os.makedirs(output_folder)\n         \n         print(\"looping over folder\")\n         for item in os.listdir(self.folder_of_models):\n-            item_path = os.path.join(self.folder_of_models, item)\n-            # Check if the item is a directory\n-            print(\"got item path\", item_path)\n-            if os.path.isdir(item_path):\n-                if \"_snapshots\" not in item_path:\n-                    continue\n-                print(\"item_path is a snapshot\")\n-                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n-                is_exp = \"threshold_in_days\" in param_df.index\n-                if self.use_exp != is_exp:\n-                    continue\n-                fdict = {}\n-                for stage_kind in stage_kinds:\n-                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n-                trajectories.append(fdict)\n-                \n-                uids.append(param_df.loc[\"uid\"].value)\n-                if \"run_number\" in param_df.index:\n-                    run_numbers.append(param_df.loc[\"run_number\"].value)\n-                    param_df = param_df.drop([\"uid\", \"run_number\"])\n-                else:\n-                    run_numbers.append(param_df.loc[\"seed\"].value)\n-                    param_df = param_df.drop([\"uid\", \"seed\"])\n-                if subreddit is None:\n-                    bn = os.path.basename(item_path)\n-                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n-                    is_exp = is_exp_sampling(param_df)\n-                    common_param_df = param_df\n-                if not compare_dataframes(param_df, common_param_df):\n-                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(param_df, sidebyside=True)\n-                    the_html += self.html_table(common_param_df, sidebyside=True)\n-                    return the_html\n-                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n-                    key_info = json.load(f)\n-                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n-                if common_key_info is None:\n-                    common_key_info = key_info\n-                if not compare_dicts(key_info, common_key_info):\n-                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                    the_html += self.html_table(key_info, sidebyside=True)\n-                    the_html += self.html_table(common_key_info, sidebyside=True)\n+            try:\n+                item_path = os.path.join(self.folder_of_models, item)\n+                # Check if the item is a directory\n+                print(\"got item path\", item_path)\n+                if os.path.isdir(item_path):\n+                    if \"_snapshots\" not in item_path:\n+                        continue\n+                    print(\"item_path is a snapshot\")\n+                    param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", engine=\"python\", names=[\"key\", \"value\"], index_col=\"key\")\n+                    is_exp = \"threshold_in_days\" in param_df.index\n+                    if self.use_exp != is_exp:\n+                        continue\n+                    fdict = {}\n+                    for stage_kind in stage_kinds:\n+                        fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n+                    trajectories.append(fdict)\n+                    \n+                    uids.append(param_df.loc[\"uid\"].value)\n+                    if \"run_number\" in param_df.index:\n+                        run_numbers.append(param_df.loc[\"run_number\"].value)\n+                        param_df = param_df.drop([\"uid\", \"run_number\"])\n+                    else:\n+                        run_numbers.append(param_df.loc[\"seed\"].value)\n+                        param_df = param_df.drop([\"uid\", \"seed\"])\n+                    if subreddit is None:\n+                        bn = os.path.basename(item_path)\n+                        subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n+                        is_exp = is_exp_sampling(param_df)\n+                        common_param_df = param_df\n+                    if not compare_dataframes(param_df, common_param_df):\n+                        the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                        the_html += self.html_table(param_df, sidebyside=True)\n+                        the_html += self.html_table(common_param_df, sidebyside=True)\n+                        return the_html\n+                    with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n+                        key_info = json.load(f)\n+                    key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n+                    if common_key_info is None:\n+                        common_key_info = key_info\n+                    if not compare_dicts(key_info, common_key_info):\n+                        the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n+                        the_html += self.html_table(key_info, sidebyside=True)\n+                        the_html += self.html_table(common_key_info, sidebyside=True)\n+            except Exception as e:\n+                print(\"got error processing item path\", item)\n+                print(e)\n+                continue\n         print(\"done looping over folder\")\n         self.param_df = common_param_df\n         self.key_info = common_key_info\n         self.uids = uids\n"
                },
                {
                    "date": 1730309963537,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -108,9 +108,9 @@\n                     \n                     uids.append(param_df.loc[\"uid\"].value)\n                     if \"run_number\" in param_df.index:\n                         run_numbers.append(param_df.loc[\"run_number\"].value)\n-                        param_df = param_df.drop([\"uid\", \"run_number\"])\n+                        param_df = param_df.drop([\"uid\", \"run_number\", \"use_run_number_as_seed\"])\n                     else:\n                         run_numbers.append(param_df.loc[\"seed\"].value)\n                         param_df = param_df.drop([\"uid\", \"seed\"])\n                     if subreddit is None:\n@@ -118,21 +118,17 @@\n                         subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n                         is_exp = is_exp_sampling(param_df)\n                         common_param_df = param_df\n                     if not compare_dataframes(param_df, common_param_df):\n-                        the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                        the_html += self.html_table(param_df, sidebyside=True)\n-                        the_html += self.html_table(common_param_df, sidebyside=True)\n-                        return the_html\n+                        print(f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\")\n                     with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n                         key_info = json.load(f)\n+                    del key_info[\"model\"]\n                     key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n                     if common_key_info is None:\n                         common_key_info = key_info\n                     if not compare_dicts(key_info, common_key_info):\n-                        the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n-                        the_html += self.html_table(key_info, sidebyside=True)\n-                        the_html += self.html_table(common_key_info, sidebyside=True)\n+                        print(f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\")\n             except Exception as e:\n                 print(\"got error processing item path\", item)\n                 print(e)\n                 continue\n"
                },
                {
                    "date": 1730732452686,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,10 +150,14 @@\n         for stage_kind in stage_kinds:\n             dfs = []\n             for fdict in trajectories:\n                 dfs.append(fdict[stage_kind])\n-            combined_df = pd.concat(dfs)\n-            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n+\n+            xlabel = y_axis_labels[stage_kind]\n+            combined_df = pd.concat([df[[xlabel, 'score']] for df in dfs])\n+            result_df = combined_df.groupby(xlabel).agg(['mean', 'std'])\n+            result_df.columns = ['score', 'std_dev']\n+            result_df = result_df.reset_index()\n             setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n             result_df.to_parquet(f\"{output_folder}/{stage_kind}_trajectory_df.parquet\")\n         results = {\n             \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n"
                },
                {
                    "date": 1730735078672,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,14 +150,14 @@\n         for stage_kind in stage_kinds:\n             dfs = []\n             for fdict in trajectories:\n                 dfs.append(fdict[stage_kind])\n-\n             xlabel = y_axis_labels[stage_kind]\n             combined_df = pd.concat([df[[xlabel, 'score']] for df in dfs])\n             result_df = combined_df.groupby(xlabel).agg(['mean', 'std'])\n             result_df.columns = ['score', 'std_dev']\n             result_df = result_df.reset_index()\n+            result_df[\"nposts\"] = dfs[0][\"nposts\"]\n             setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n             result_df.to_parquet(f\"{output_folder}/{stage_kind}_trajectory_df.parquet\")\n         results = {\n             \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n"
                },
                {
                    "date": 1730743386503,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -179,11 +179,11 @@\n         # source, fn, fv, fk, marker_size=8\n         rclass = BuildAverageTrajectoryReport(results, \"nposts\", self.min_posts, \">=\")\n         the_html = rclass.render_content()\n         if self.use_exp:\n-            fname = f\"{subreddit}_avg_exp\"\n+            fname = f\"{subreddit}_avg_exp_error\"\n         else:\n-            fname = f\"{subreddit}_avg\"\n+            fname = f\"{subreddit}_avg_error\"\n         with open(f\"{output_folder}/{fname}.html\", \"w\") as f:\n             f.write(the_html)\n         with open(f\"{output_folder}/{fname}_results.pkl\", \"wb\") as f:\n             pickle.dump(results, f)\n"
                }
            ],
            "date": 1730058044759,
            "name": "Commit-0",
            "content": "print(\"starting\")\nimport pickle\nimport json\nimport sys\nimport pickle\nimport os\nimport pandas as pd\nfrom pandas import Timedelta\nimport re\nimport json\n\nfrom build_average_trajectory_report import BuildAverageTrajectoryReport\nfrom utilities import html_table\n\ny_axis_labels = {\n    \"num_phases\": \"phase\",\n    \"raw_post_count\": \"posts\",\n    \"time\": \"weeks\",\n    \"experience\": \"pseudo weeks\",\n    \"ntokens_bins\": \"ntokens\"\n}\n\nstage_kinds = [\"num_phases\", \"raw_post_count\", \"time\", \"experience\"]\n\ndef ds(text):\n    print(text)\n\ndef load_pickle_or_parquet(path):\n    fname, ext = os.path.splitext(path)\n    if ext == \".parquet\":\n        return pd.read_parquet(path)\n    else:\n        return pd.read_pickle(path)\n\ndef is_exp_sampling(param_df):\n    return \"threshold_in_days\" in param_df.index\n\ndef compare_dataframes(df1, df2):\n    if df1.index.equals(df2.index) and (df1['value'] == df2['value']).all():\n        return True\n    else:\n        return False\n\ndef compare_dicts(d1, d2):\n    for k in d1.keys():\n        if not d1[k] == d2[k]:\n            return False\n    return True\n    \n\nprint(\"done with globals\")\nclass AverageTrajectories():\n    def __init__(self, folder_of_models, exp, min_posts=2000):\n        self.folder_of_models = folder_of_models\n        self.html_table = html_table\n        self.min_posts = min_posts\n        self.exp = exp\n        return\n\n    def display_status(self, text):\n        print(text)\n\n    def render_content(self):\n        trajectories = []\n        params = []\n        \n        subreddit = None\n        \n        uids = []\n        seeds = []\n        \n        common_param_df = None\n        common_key_info = None\n        \n        for item in os.listdir(self.folder_of_models):\n            item_path = os.path.join(self.folder_of_models, item)\n            # Check if the item is a directory\n            if os.path.isdir(item_path):\n                fdict = {}\n                for stage_kind in stage_kinds:\n                    fdict[stage_kind] = load_pickle_or_parquet(f\"{item_path}/{stage_kind}_trajectory_df.parquet\")\n                trajectories.append(fdict)\n                param_df = pd.read_csv(f\"{item_path}/parameters.txt\", sep=\":\\t\", names=[\"key\", \"value\"], index_col=\"key\")\n                uids.append(param_df.loc[\"uid\"].value)\n                seeds.append(param_df.loc[\"seed\"].value)\n                param_df = param_df.drop([\"uid\", \"seed\"])\n                if subreddit is None:\n                    bn = os.path.basename(item_path)\n                    subreddit = re.findall(\"^(.*?)_snapshots\", bn)[0]\n                    is_exp = is_exp_sampling(param_df)\n                    common_param_df = param_df\n                if not compare_dataframes(param_df, common_param_df):\n                    the_html = f\"Got unmatched params for uid {uids[-1]} with original uid {uids[0]}<br>\"\n                    the_html += self.html_table(param_df, sidebyside=True)\n                    the_html += self.html_table(common_param_df, sidebyside=True)\n                    return the_html\n                with open(f\"{item_path}/trajectory_key_info.json\", \"r\") as f:\n                    key_info = json.load(f)\n                key_info[\"k\"] = round(float(key_info[\"k\"]), 1)\n                if common_key_info is None:\n                    common_key_info = key_info\n                if not compare_dicts(key_info, common_key_info):\n                    the_html = f\"Got unmatched key_info for uid {uids[-1]} with original uid {uids[0]}<br>\"\n                    the_html += self.html_table(key_info, sidebyside=True)\n                    the_html += self.html_table(common_key_info, sidebyside=True)\n        \n        self.param_df = common_param_df\n        self.key_info = common_key_info\n        self.uids = uids\n        self.seeds = seeds\n        self.subreddit = subreddit\n        self.is_exp = is_exp\n        \n        if self.is_exp:\n            self.table_html = f\"<h4>{subreddit}_exp</h4>\"\n        else:\n            self.table_html = f\"<h4>{subreddit}</h4>\"\n        self.table_html += self.html_table(common_param_df, sidebyside=True)\n        self.table_html += self.html_table(common_key_info, sidebyside=True)\n        self.table_html += \"<br>\"\n        ds(\"computing averages\")\n        for stage_kind in stage_kinds:\n            dfs = []\n            for fdict in trajectories:\n                dfs.append(fdict[stage_kind])\n            combined_df = pd.concat(dfs)\n            result_df = combined_df.groupby(y_axis_labels[stage_kind]).mean().reset_index()\n            setattr(self, f\"{stage_kind}_trajectory_df\", result_df)\n        results = {\n            \"num_phases_trajectory_df\": getattr(Tile, \"num_phases_trajectory_df\"),\n            \"raw_post_count_trajectory_df\": getattr(Tile, \"raw_post_count_trajectory_df\"),\n            \"time_trajectory_df\": getattr(Tile, \"time_trajectory_df\"),\n            \"experience_trajectory_df\": getattr(Tile, \"experience_trajectory_df\"),\n            # \"ntokens_bins_trajectory_df\": getattr(Tile, \"ntokens_bins_trajectory_df\"),\n            \"param_df\": getattr(Tile, \"param_df\"),\n            \"key_info\": getattr(Tile, \"key_info\"),\n            \"uids\": getattr(Tile, \"uids\"),\n            \"subreddit\": getattr(Tile, \"subreddit\"),\n            \"seeds\": getattr(Tile, \"seeds\"),\n            \"is_exp\": getattr(Tile, \"is_exp\"),\n        }\n\n        rclass = BuildAverageTrajectoryReport(results, min_posts=self.min_posts)\n        the_html = rclass.render_content()\n        if is_exp:\n            fname = f\"{subreddit}_avg_exp\"\n        else:\n            fname = f\"{subreddit}_avg\"\n        with open(f\"{self.folder_of_models}/{fname}.html\", \"w\") as f:\n            f.write(the_html)\n\nif __name__ == '__main__':\n    print(\"starting\")\n    exp = sys.argv[2].lower() == 'true'\n    Tile = AverageTrajectories(sys.argv[1], exp, sys.argv[3])\n    Tile.render_content()"
        }
    ]
}