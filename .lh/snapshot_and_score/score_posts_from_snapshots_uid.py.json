{
    "sourceFile": "snapshot_and_score/score_posts_from_snapshots_uid.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1729807669902,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1731370501680,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,10 @@\n+### The script reads the {subreddit}_df_true dataframe and the snapshots, and scores the posts\n+### The script saves the scored dataframe to {subreddit}_scored_{uid}.parquet\n+### The script reads the parameters from {subreddit}_snapshots_{uid}/parameters.txt\n+### The saved dataframe has the following columns:\n+### author, post_id, seconds, subreddit, total_user_posts, post_number, true_date, experience, uid\n+\n print(\"starting score_posts_from_snapshots.py\")\n import pickle\n import json\n import pickle\n"
                }
            ],
            "date": 1729807669902,
            "name": "Commit-0",
            "content": "print(\"starting score_posts_from_snapshots.py\")\nimport pickle\nimport json\nimport pickle\nimport os, sys\nimport pandas as pd\nfrom nltk.util import bigrams\nfrom katz_class import KatzBigramLM\nfrom typing import *\n\n\nkb_model = None\ntruncate_text = None\nmax_len = None\n\nmonth_list = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\",\n             \"September\", \"October\", \"November\", \"December\"]\n\ndef month_number(month_name):\n    return 1 + month_list.index(month_name)\n\ndef month_name(month_number):\n    return month_list[month_number - 1]\n\ndef score_function(txt):\n    # if truncate_text:\n    #     return kb_model.entropy(list(bigrams(txt[:max_len])))\n    return kb_model.entropy(list(bigrams(txt)))\n\ndef load_pickle_or_parquet(path):\n    fname, ext = os.path.splitext(path)\n    if ext == \".parquet\":\n        return pd.read_parquet(path)\n    else:\n        return pd.read_pickle(path)\n\ndef ds(text):\n    print(text)\n    return\n\nprint(\"done with globals\")\nparams = []\nclass ScorePostsFromSnapshots():\n    def __init__(self, jsonfile, subreddit, base_path, uid):\n        self.uid = uid\n        self.subreddit_name = subreddit\n        self.working_directory = f\"{base_path}/{self.subreddit_name}\"\n\n        with open(jsonfile, 'r') as file:\n            config = json.load(file)\n        for param in params:\n            if param in config:\n                setattr(self, param, config[param])\n            else:\n                setattr(self, param, None)\n\n        self.text_df_file = f\"{self.working_directory}/{self.subreddit_name}_df_true.parquet\"\n        self.snapshot_folder = f\"{self.working_directory}/{self.subreddit_name}_snapshots_{self.uid}\"\n        self.output_path = f\"{self.snapshot_folder}/{self.subreddit_name}_scored_{self.uid}.parquet\"\n        return\n\n    def display_status(self, text):\n        print(text)\n\n    def pull_param_vals(self):\n        param_df = pd.read_csv(f\"{self.snapshot_folder}/parameters.txt\", sep=\":\\t\", names=[\"key\", \"value\"], index_col=\"key\")\n        keys = param_df.index.tolist()\n        for key in keys:\n            setattr(self, key, param_df.loc[key].value)\n        return\n\n    def render_content(self):\n        ds(\"Getting snapshot params\")\n        global kb_model\n        global truncate_text\n        global max_len\n        self.pull_param_vals()\n        truncate_text = self.truncate_text\n        max_len = int(self.max_len)\n        ds(\"Reading text df\")\n        text_df = load_pickle_or_parquet(self.text_df_file)\n        if \"post_id\" in text_df.columns:\n            text_df.set_index('post_id', inplace=True)\n        ds(\"Removing text_df duplicates\")\n        text_df = text_df[~text_df.index.duplicated(keep='first')]\n        ds(\"Reading score df\")\n\n        text_df[self.uid] = -999\n        smonth_num = int(self.start_month)\n        emonth_num = int(self.end_month)\n        self.start_year = int(self.start_year)\n        self.end_year = int(self.end_year)\n        for year in range(self.start_year, self.end_year + 1):\n            smonth = smonth_num if year == self.start_year else 1\n            emonth = emonth_num if year == self.end_year else 12\n            \n            for month in range(smonth, emonth + 1):\n                ds(f\"Processing year {year} month {month}\")\n                month_df = text_df[(text_df['true_date'].dt.year == year) & (text_df['true_date'].dt.month == month)]\n                with open(f\"{self.snapshot_folder}/snapshots/{month_name(month)}-{year}\", \"rb\") as f:\n                    snapshot_dict = pickle.load(f)\n                kb_model = KatzBigramLM(50, .9)\n                kb_model.__setstate__(snapshot_dict[\"lm_dict\"])\n                used_posts = snapshot_dict[\"post_ids\"]\n                month_df = month_df[~month_df.index.isin(used_posts)]\n                results = month_df['text'].apply(score_function)\n                text_df.loc[results.index, self.uid] = results\n        \n        ds(\"writing the file\")        \n        text_df.drop(columns=['text'], inplace=True)\n        text_df.to_parquet(self.output_path)\n\nif __name__ == '__main__':\n    print(\"starting\")\n    Tile = ScorePostsFromSnapshots(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])\n    Tile.render_content()"
        }
    ]
}